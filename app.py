import streamlit as st
from huggingface_hub import InferenceClient
import os

# --- 1. Definici贸n del Rol y Configuraci贸n Inicial ---

# Tu clave de API de Hugging Face
# Es mejor usar st.secrets para producci贸n, pero para desarrollo local esto funciona.
# O puedes pedirla en la UI.
HF_API_KEY = os.environ.get("HF_API_KEY") # O usa st.text_input("Hugging Face API Key", type="password")

MASTER_PROMPT = """
[INICIO DE LA DEFINICIN DEL ROL]
**Nombre del Rol:** Investigador Doctoral IA (IDA)
**Objetivo Principal:** Asistir en la investigaci贸n y redacci贸n de una tesis doctoral en el campo de la Econom铆a Aplicada. Tu funci贸n es ser un colaborador riguroso, anal铆tico y eficiente.
**Personalidad:** Eres un asistente de investigaci贸n post-doctoral; preciso, met贸dico y objetivo.
**reas de Especializaci贸n:**
1. **Analista de Literatura Acad茅mica:** Resume papers identificando pregunta de investigaci贸n, metodolog铆a, resultados, contribuci贸n y limitaciones.
2. **Razonador Econ贸mico-Matem谩tico:** Explica conceptos, desarrolla derivaciones matem谩ticas paso a paso e interpreta modelos.
3. **Generador de C贸digo (Especialista en CODEQwen):** Genera c贸digo Python funcional, comentado y con sus dependencias para tareas de an谩lisis de datos.
**Instrucciones de Interacci贸n:** Identifica la tarea, aplica el formato de salida correcto y prioriza la integridad acad茅mica.
[FIN DE LA DEFINICIN DEL ROL]
"""

# --- 2. Interfaz de Streamlit ---

st.set_page_config(layout="wide", page_title="Asistente de Tesis Doctoral IA")

st.title(" Asistente de Tesis Doctoral IA")
st.markdown("Una herramienta para potenciar tu investigaci贸n doctoral usando IA.")

# --- Configuraci贸n en la barra lateral ---
st.sidebar.header("Configuraci贸n")
hf_api_key_input = st.sidebar.text_input("Hugging Face API Key", type="password", help="Pega tu clave de API de Hugging Face aqu铆.")

# Selecci贸n de modelos
st.sidebar.subheader("Selecci贸n de Modelos")
model_reasoning = st.sidebar.selectbox(
    "Modelo para Resumen y Razonamiento",
    ["mistralai/Mixtral-8x7B-Instruct-v0.1", "meta-llama/Llama-2-70b-chat-hf", "google/gemma-7b-it"],
    help="Modelos grandes son mejores para entender textos complejos."
)
model_coding = st.sidebar.selectbox(
    "Modelo para C贸digo (CODEQwen)",
    ["Qwen/CodeQwen1.5-7B-Chat", "codellama/CodeLlama-34b-Instruct-hf"],
    help="Modelos especializados en c贸digo."
)


# --- 3. Funcionalidad de la App en Pesta帽as ---

tab1, tab2, tab3 = st.tabs([" Resumir Paper", " Razonamiento Econ贸mico/Matem谩tico", " Generar C贸digo"])

# Funci贸n para llamar a la API de Hugging Face
def get_hf_response(api_key, model, prompt):
    if not api_key:
        st.error("Por favor, introduce tu Hugging Face API Key en la barra lateral.")
        return None
    try:
        client = InferenceClient(token=api_key)
        response = client.text_generation(prompt=prompt, model=model, max_new_tokens=2048)
        return response
    except Exception as e:
        st.error(f"Error al contactar la API de Hugging Face: {e}")
        return None

# Pesta帽a 1: Resumir Paper
with tab1:
    st.header("Analista de Literatura Acad茅mica")
    paper_text = st.text_area("Pega aqu铆 el abstract o el texto completo del paper:", height=300)
    if st.button("Generar Resumen", key="summarize"):
        if paper_text:
            with st.spinner("Analizando el texto y generando resumen..."):
                final_prompt = f"{MASTER_PROMPT}\n\n**Tarea Actual:** Realizar un an谩lisis de literatura acad茅mica sobre el siguiente texto. Sigue estrictamente el formato de salida para 'Analista de Literatura Acad茅mica'.\n\n**Texto a Analizar:**\n```\n{paper_text}\n```\n\n**An谩lisis Detallado:**"
                summary = get_hf_response(hf_api_key_input, model_reasoning, final_prompt)
                if summary:
                    st.markdown(summary)
        else:
            st.warning("Por favor, pega el texto de un paper.")

# Pesta帽a 2: Razonamiento
with tab2:
    st.header("Razonador Econ贸mico-Matem谩tico")
    question_text = st.text_area("Escribe tu pregunta o el problema a resolver:", height=200)
    if st.button("Obtener Razonamiento", key="reason"):
        if question_text:
            with st.spinner("Procesando la solicitud..."):
                final_prompt = f"{MASTER_PROMPT}\n\n**Tarea Actual:** Responder a la siguiente pregunta de razonamiento econ贸mico/matem谩tico. Proporciona una explicaci贸n clara, l贸gica y, si es necesario, paso a paso.\n\n**Pregunta:**\n```\n{question_text}\n```\n\n**Respuesta Detallada:**"
                reasoning = get_hf_response(hf_api_key_input, model_reasoning, final_prompt)
                if reasoning:
                    st.markdown(reasoning)
        else:
            st.warning("Por favor, introduce una pregunta.")

# Pesta帽a 3: Generar C贸digo
with tab3:
    st.header("Generador de C贸digo con CODEQwen")
    code_description = st.text_area("Describe la tarea de programaci贸n que necesitas:", height=200)
    if st.button("Generar C贸digo", key="code"):
        if code_description:
            with st.spinner("Escribiendo el c贸digo..."):
                final_prompt = f"{MASTER_PROMPT}\n\n**Tarea Actual:** Generar c贸digo seg煤n la siguiente descripci贸n. Utiliza la especializaci贸n 'Generador de C贸digo (Especialista en CODEQwen)' para producir un c贸digo claro, comentado y con sus dependencias.\n\n**Descripci贸n de la Tarea:**\n```\n{code_description}\n```\n\n**C贸digo Generado:**"
                code = get_hf_response(hf_api_key_input, model_coding, final_prompt)
                if code:
                    # Los modelos de c贸digo a menudo devuelven el c贸digo dentro de bloques ```python ... ```
                    # Podemos intentar extraerlo o simplemente mostrarlo todo.
                    st.code(code, language='python')
        else:
            st.warning("Por favor, describe la tarea de programaci贸n.")

import streamlit as st
from huggingface_hub import InferenceClient

# --- 1. Definici贸n del Rol y Configuraci贸n Inicial ---
# Se define un prompt maestro para darle contexto y personalidad al asistente de IA.
MASTER_PROMPT = """
[INICIO DE LA DEFINICIN DEL ROL]
**Nombre del Rol:** Investigador Doctoral IA (IDA)
**Objetivo Principal:** Asistir en la investigaci贸n y redacci贸n de una tesis doctoral en el campo de la Econom铆a Aplicada. Tu funci贸n es ser un colaborador riguroso, anal铆tico y eficiente.
**Personalidad:** Eres un asistente de investigaci贸n post-doctoral; preciso, met贸dico y objetivo.
**reas de Especializaci贸n:**
1. **Analista de Literatura Acad茅mica:** Resume papers identificando pregunta de investigaci贸n, metodolog铆a, resultados, contribuci贸n y limitaciones.
2. **Razonador Econ贸mico-Matem谩tico:** Explica conceptos, desarrolla derivaciones matem谩ticas paso a paso e interpreta modelos.
3. **Generador de C贸digo (Especialista en CODEQwen):** Genera c贸digo Python funcional, comentado y con sus dependencias para tareas de an谩lisis de datos.
**Instrucciones de Interacci贸n:** Identifica la tarea, aplica el formato de salida correcto y prioriza la integridad acad茅mica.
[FIN DE LA DEFINICIN DEL ROL]
"""

# --- 2. Interfaz de Streamlit ---
st.set_page_config(layout="wide", page_title="Asistente de Tesis Doctoral IA")

# Barra lateral para configuraci贸n
st.sidebar.header("Configuraci贸n")

# Input para la API Key de Hugging Face, con manejo de secretos de Streamlit
try:
    HF_API_KEY_FROM_SECRETS = st.secrets["HF_API_KEY"]
except (FileNotFoundError, KeyError):
    HF_API_KEY_FROM_SECRETS = ""

hf_api_key_input = st.sidebar.text_input(
    "Hugging Face API Key", 
    type="password", 
    value=HF_API_KEY_FROM_SECRETS,
    help="Pega tu clave aqu铆 si corres la app localmente. En la nube, se configura v铆a st.secrets."
)

st.sidebar.subheader("Selecci贸n de Modelos")
model_reasoning = st.sidebar.selectbox(
    "Modelo para Resumen y Razonamiento",
    ["mistralai/Mixtral-8x7B-Instruct-v0.1", "meta-llama/Meta-Llama-3-8B-Instruct", "microsoft/Phi-3-mini-4k-instruct", "google/gemma-7b-it"],
    key="model_reasoning_select"
)
model_coding = st.sidebar.selectbox(
    "Modelo para C贸digo (CODEQwen)",
    ["Qwen/CodeQwen1.5-7B-Chat", "codellama/CodeLlama-34b-Instruct-hf", "bigcode/starcoder2-15b"],
    key="model_coding_select"
)

# --- 3. L贸gica Principal de la App ---
# Definici贸n de las pesta帽as de la interfaz principal
tab1, tab2, tab3 = st.tabs([" Resumir Paper", " Razonamiento Econ贸mico/Matem谩tico", " Generar C贸digo"])


def get_hf_response(api_key, model, prompt):
    """
    Funci贸n central para contactar la API de Hugging Face.
    Maneja la autenticaci贸n, la llamada a la API y la gesti贸n de errores.
    """
    if not api_key or not api_key.startswith("hf_"):
        st.error("Por favor, introduce una Hugging Face API Key v谩lida.")
        st.stop()

    try:
        # Crea el cliente de inferencia con el token proporcionado
        client = InferenceClient(token=api_key)
        messages = [{"role": "user", "content": prompt}]
        
        # Realiza la llamada a la API usando el m茅todo chat_completion
        response = client.chat_completion(
            messages=messages,
            model=model,
            max_tokens=4096,
        )
        return response.choices[0].message.content
        
    except Exception as e:
        # Esta secci贸n se activa si la llamada a la API falla, replicando el error de la imagen
        st.error(f"Error al contactar la API de Hugging Face. Detalles:")
        st.info("Esto puede ocurrir por varias razones:\n"
                "1. No tienes acceso a este modelo (visita su p谩gina en HF para solicitarlo).\n"
                "2. El modelo est谩 tardando en cargar en los servidores de Hugging Face. Por favor, espera un minuto y vuelve a intentarlo.\n"
                "3. La API Key es incorrecta o no tiene los permisos necesarios.")
        print(f"Detalle del error: {e}") # Imprime el error real en la consola para depuraci贸n
        return None

# Contenido de la Pesta帽a 1: Resumir Paper
with tab1:
    st.header("Analista de Literatura Acad茅mica")
    paper_text = st.text_area("Pega aqu铆 el abstract o el texto completo del paper:", height=300, key="paper_text")
    if st.button("Generar Resumen", key="summarize"):
        if paper_text:
            with st.spinner("Analizando..."):
                final_prompt = f"{MASTER_PROMPT}\n\n**Tarea Actual:** Resumir el siguiente paper acad茅mico.\n\n**Texto a Analizar:**\n```\n{paper_text}\n```\n\n**An谩lisis Detallado:**"
                summary = get_hf_response(hf_api_key_input, model_reasoning, final_prompt)
                if summary: st.markdown(summary)
        else: st.warning("Por favor, pega el texto de un paper.")

# Contenido de la Pesta帽a 2: Razonamiento
with tab2:
    st.header("Razonador Econ贸mico-Matem谩tico")
    question_text = st.text_area("Escribe tu pregunta o el problema a resolver:", height=200, key="question_text")
    if st.button("Obtener Razonamiento", key="reason"):
        if question_text:
            with st.spinner("Procesando..."):
                final_prompt = f"{MASTER_PROMPT}\n\n**Tarea Actual:** Responder a una pregunta de econom铆a/matem谩ticas.\n\n**Pregunta:**\n```\n{question_text}\n```\n\n**Respuesta Detallada:**"
                reasoning = get_hf_response(hf_api_key_input, model_reasoning, final_prompt)
                if reasoning: st.markdown(reasoning)
        else: st.warning("Por favor, introduce una pregunta.")

# Contenido de la Pesta帽a 3: Generar C贸digo (la que se muestra en la imagen)
with tab3:
    st.header("Generador de C贸digo con CODEQwen")
    code_description = st.text_area("Describe la tarea de programaci贸n que necesitas:", height=100, key="code_desc", value="Me podr铆as ayudar con un c贸digo de para un modelo de dsge con Quantecon")
    if st.button("Generar C贸digo", key="code"):
        if code_description:
            with st.spinner("Escribiendo c贸digo..."):
                final_prompt = f"{MASTER_PROMPT}\n\n**Tarea Actual:** Generar c贸digo Python basado en la siguiente descripci贸n.\n\n**Descripci贸n de la Tarea:**\n```\n{code_description}\n```\n\n**C贸digo Generado:**"
                code = get_hf_response(hf_api_key_input, model_coding, final_prompt)
                if code:
                    # Limpia el output para mostrar solo el bloque de c贸digo
                    try:
                        code_block = code.split("```python")[1].split("```")[0]
                        st.code(code_block.strip(), language='python')
                    except IndexError:
                         # Si el formato no es el esperado, muestra la respuesta completa
                        st.code(code, language='python')
        else: st.warning("Por favor, describe la tarea de programaci贸n.")

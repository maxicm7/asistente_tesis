import streamlit as st
from huggingface_hub import InferenceClient

# --- Configuraci贸n de la p谩gina ---
# El estado inicial de la barra lateral se puede configurar aqu铆
st.set_page_config(
    layout="wide", 
    page_title="Asistente de Tesis Doctoral IA",
    initial_sidebar_state="expanded" # 'auto', 'expanded', or 'collapsed'
)

# --- Definici贸n del Rol (Master Prompt) ---
MASTER_PROMPT = """
[INICIO DE LA DEFINICIN DEL ROL]
**Nombre del Rol:** Investigador Doctoral IA (IDA)
**Objetivo Principal:** Asistir en la investigaci贸n y redacci贸n de una tesis doctoral en el campo de la Econom铆a Aplicada. Tu funci贸n es ser un colaborador riguroso, anal铆tico y eficiente.
[FIN DE LA DEFINICIN DEL ROL]
"""

# --- Interfaz de la Barra Lateral (Sidebar) ---
with st.sidebar:
    st.header("Configuraci贸n")

    # Intenta obtener la API key desde los secretos de Streamlit, si no, deja el campo vac铆o.
    try:
        HF_API_KEY_FROM_SECRETS = st.secrets["HF_API_KEY"]
    except (FileNotFoundError, KeyError):
        HF_API_KEY_FROM_SECRETS = ""

    hf_api_key_input = st.text_input(
        "Hugging Face API Key", 
        type="password", 
        value=HF_API_KEY_FROM_SECRETS,
        help="Introduce tu API Key de Hugging Face. Es necesaria para usar los modelos."
    )

    st.subheader("Selecci贸n de Modelos")
    model_reasoning = st.selectbox(
        "Modelo para Resumen y Razonamiento",
        ["mistralai/Mixtral-8x7B-Instruct-v0.1", "meta-llama/Meta-Llama-3-8B-Instruct"],
        key="model_reasoning_select"
    )
    model_coding = st.selectbox(
        "Modelo para C贸digo (CODEQwen)",
        ["Qwen/CodeQwen1.5-7B-Chat", "codellama/CodeLlama-34b-Instruct-hf"],
        key="model_coding_select"
    )


# --- L贸gica de la API de Hugging Face ---
def get_hf_response(api_key, model, prompt):
    """
    Funci贸n para llamar a la API de Inferencia de Hugging Face.
    Incluye el manejo de errores que se muestra en la captura de pantalla.
    """
    if not api_key or not api_key.startswith("hf_"):
        st.error("Por favor, introduce una Hugging Face API Key v谩lida en la barra lateral.")
        return None

    try:
        client = InferenceClient(token=api_key)
        messages = [{"role": "user", "content": prompt}]
        
        response = client.chat_completion(
            messages=messages,
            model=model,
            max_tokens=4096,
        )
        return response.choices[0].message.content
    
    # Esta secci贸n es crucial para replicar el error que se muestra en la imagen
    except Exception as e:
        st.error("Error al contactar la API de Hugging Face. Detalles:")
        st.info(
            "Esto puede ocurrir por varias razones:\n"
            "1. No tienes acceso a este modelo (visita su p谩gina en HF para solicitarlo).\n"
            "2. El modelo est谩 tardando en cargar en los servidores de Hugging Face. Por favor, espera un minuto y vuelve a intentarlo.\n"
            "3. La API Key es incorrecta o no tiene los permisos necesarios."
        )
        # Opcional: imprimir el error real en la consola del servidor para depuraci贸n
        print(f"Detalle completo del error: {e}") 
        return None


# --- Estructura Principal de la Aplicaci贸n ---
# No se necesita el t铆tulo principal aqu铆, ya que cada pesta帽a tiene su propio encabezado.

# Definici贸n de las pesta帽as
tab1, tab2, tab3 = st.tabs([" Resumir Paper", " Razonamiento Econ贸mico/Matem谩tico", " Generar C贸digo"])

# Pesta帽a 1: Resumir Paper
with tab1:
    st.header("Analista de Literatura Acad茅mica")
    paper_text = st.text_area("Pega aqu铆 el abstract o el texto completo del paper:", height=250, key="paper_text")
    if st.button("Generar Resumen", key="summarize"):
        if paper_text:
            with st.spinner("Analizando..."):
                final_prompt = f"{MASTER_PROMPT}\n**Tarea:** Resumir el siguiente texto acad茅mico.\n**Texto:**\n{paper_text}"
                summary = get_hf_response(hf_api_key_input, model_reasoning, final_prompt)
                if summary: 
                    st.markdown(summary)
        else:
            st.warning("Por favor, pega el texto de un paper.")

# Pesta帽a 2: Razonamiento Econ贸mico/Matem谩tico
with tab2:
    st.header("Razonador Econ贸mico-Matem谩tico")
    question_text = st.text_area("Escribe tu pregunta o el problema a resolver:", height=200, key="question_text")
    if st.button("Obtener Razonamiento", key="reason"):
        if question_text:
            with st.spinner("Procesando..."):
                final_prompt = f"{MASTER_PROMPT}\n**Tarea:** Responder la siguiente pregunta.\n**Pregunta:**\n{question_text}"
                reasoning = get_hf_response(hf_api_key_input, model_reasoning, final_prompt)
                if reasoning: 
                    st.markdown(reasoning)
        else:
            st.warning("Por favor, introduce una pregunta.")

# Pesta帽a 3: Generar C贸digo (la que se muestra en la imagen)
with tab3:
    st.header("Generador de C贸digo con CODEQwen")
    # A
    #     JUSTE AQU: El valor del `text_area` ahora coincide exactamente con la nueva imagen.
    code_description = st.text_area(
        "Describe la tarea de programaci贸n que necesitas:", 
        height=100, 
        key="code_desc", 
        value="Me podr铆as ayudar con un c贸digo de python para un modelo de dsge con Quantecon"
    )
    if st.button("Generar C贸digo", key="code"):
        if code_description:
            with st.spinner("Escribiendo c贸digo..."):
                final_prompt = f"{MASTER_PROMPT}\n**Tarea:** Generar c贸digo Python.\n**Descripci贸n:**\n{code_description}"
                code = get_hf_response(hf_api_key_input, model_coding, final_prompt)
                if code:
                    st.code(code, language='python')
        else:
            st.warning("Por favor, describe la tarea de programaci贸n.")
